{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Neural Network\n",
    " \n",
    "###  <div align=center> Moon Il-chul(icmoon@kaist.ac.kr); Shin Dong-hyeok(tlsehdgur0@kaist.ac.kr) </div> \n",
    " \n",
    "본 코드는 MNIST 데이터셋을 이용한 Single Neural Network의 구현 예시입니다.  \n",
    "본 코드를 통해서 Single Neural Network에서 initialization, forward pass, backpropagation 등을 학습할 수 있습니다.\n",
    "\n",
    "## MNIST 데이터셋\n",
    "\n",
    "MNIST 데이터셋은 0~9의 정수를 손으로 작성하여 28$\\times$28 픽셀의 이미지로 구성된 거대한 데이터셋으로 머신러닝에서 성능을 측정해보는 벤치마크로서 널리 사용되고 있습니다.. MNIST 데이터셋은 약 60000개의 training set(mnist.train), 10000개의 test set(mnist.test)로 구성되어 있습니다. 또한 각각의 training set과 test set은 image와 label, 두 부분으로 나눌 수 있습니다. Image는 28$\\times$28 픽셀을 28$\\times$28=784차원 벡터로 저장되어있으며, label은 0~9까지 10개의 class이므로 10차원 벡터로 해당 이미지의 라벨을 저장합니다. MNIST 데이터셋은 http://yann.lecun.com/exdb/mnist/ 에서 직접 다운로드할 수도 있고, tesorflow를 이용한 코드를 통해 데이터를 다운받을 수 있습니다. \n",
    "\n",
    "## Single Neural Network\n",
    "\n",
    "인공 뉴런(Artificial Neuron)은 생물학적인 뉴런의 역할과 구조를 인공적으로 만들어낸 하나의 Unit으로, Input 정보를 input activation function과 output activation function을 거치면서 정보를 전달하는 구조입니다. 인공 뉴런의 Input activation function과 output activation function은 아래와 같은 방식으로 진행됩니다.\n",
    "* Neuron input activation function, linear sum\n",
    "    $$a(X)=b+\\sum_{i} w_ix_i$$\n",
    "* Neuron output activation function, function g\n",
    "    $$y=g(a(X))$$  \n",
    "    \n",
    "일반적으로 output activation function g로 sigmoid function을 사용하며, 이의 예시로는 logistic function, Hyperbolic tangent function, ReLU function 등이 있습니다.\n",
    "\n",
    "인공신경망(Artificial Neural Network, ANN)은 여러 개의 인공 뉴런을 조합하여 네트워크형 구조를 갖는 것을 의미합니다. 인공신경망은 data를 입력하는 Input layer, 최종 결과물을 출력하는 Output layer 그리고 이 두 layer 사이에 존재하는 Hidden layer로 구성되어 있습니다. 이 중에서 Single Neural Network는 단일 Hidden layer를 갖는 인공신경망을 의미합니다.   \n",
    "단일 Hidden layer를 갖는 Single Neural Network에서 정보의 전달은 아래와 같은 방식으로 진행됩니다. \n",
    "* Hidden layer input activation function, linear sum  \n",
    "    $$a(X)=b_1+W_1X$$  \n",
    "    이때, $W_1$는 Input layer dimension $\\times$ hidden layer dimension 행렬\n",
    "* Hidden layer output activation function, function g\n",
    "    $$h(X)=g(a(X))$$  \n",
    "    \n",
    "* Output layer output activation function, function o\n",
    "    $$f(X)=o(b_2+W_2h(X))$$  \n",
    "    이때, $W_2$는 hidden layer dimension $\\times$ output layer dimension 행렬\n",
    "    \n",
    "본 코드에서는 MNIST 데이터셋을 사용하므로 Input layer는 28$\\times$28 픽셀을 변환한 784차원의 벡터, Hidden layer는 설정값 n차원 벡터, Output layer는 각 image의 label인 10차원 벡터로 구성되어 있습니다.\n",
    "\n",
    "### Weight Initialization\n",
    "\n",
    "인공신경망에서 weight는 학습의 주체이므로 이의 초기값 설정은 매우 중요한 이슈입니다. bias는 단어 그대로 초기값을 적절한 상수로 설정하여도 큰 문제가 없습니다. 그러나 모든 weight를 같은 값으로 설정하면 인공신경망이 symmetric해져서 randomness가 사라져 효과적인 학습을 방해할 수 있습니다. 더욱이 weight를 0으로 설정하면 Input X에 상관없이 곱셈으로 연결된 $W \\times X$ term이 0이 되어서 무의미해집니다.     \n",
    "이러한 문제를 해결하기 위해 weight를 적절한 distribution에서 임의로 sampling하는 방법을 사용합니다. 본 코드에서는 아래와 같은 방식으로 bias와 weight의 초기값을 설정하였습니다.  \n",
    "    $$b_i, w_i ~ U[-\\sqrt{\\frac{6}{n_{i-1} + n_{i}}},\\sqrt{\\frac{6}{n_{i} + n_{i+1}}}]$$\n",
    "    $$n_k : k번째 layer의 node 갯수$$\n",
    "    \n",
    "### Backpropagation \n",
    "본 코드는 MNIST 데이터셋을 이용한 Supervised learning이므로 적절한 loss function을 설정하여 loss를 감소하는 방향으로 parameter를 학습합니다. 먼저 loss function은 target value와 output value의 차이를 이용한 RSS 형태로 정의했습니다.  \n",
    "$$E=\\frac{1}{2}(\\sum_{k} (t_k-o_k)^2)$$  \n",
    "앞서 언급했듯이 인공신경망에서 학습해야하는 parameter는 weight이므로, 반복된 training을 통해 weight를 지속적으로 update 해야합니다. 우리는 weight를 update 하기 위해 널리 사용하는 경사하강법(gradient descent method)를 사용하였습니다. Single Depth Layer의 경우,\n",
    "$$w_{jk}^{t+1} \\leftarrow w_{jk}^t - \\eta \\frac{\\partial E}{\\partial w_{jk}}$$  \n",
    "우리는 loss function이 $w_{jk}$에 영향을 받는다는 직관적 사실을 관찰할 수 있지만, 실제 gradient를 구할 수는 없기 때문에 chain rule을 통해 $\\frac{\\partial E}{\\partial w_{jk}}$를 구할 수 있습니다. 이때, 본 코드에서는 logistic function을 output activation function $\\sigma$으로 사용하였고, logistic function의 derivative는 다음 성질을 갖습니다.\n",
    "$$\\frac{d}{dx} f(x)=\\frac{d}{dx}(1+e^{-x})^{-1}=e^{-x}(1+e^{-x})^{-2}=f(x)(1-f(x)) $$\n",
    "위 성질과 chain rule을 이용하면 $\\frac{\\partial E}{\\partial w_{jk}}$을 구할 수 있습니다.   \n",
    "Let $ net_k = \\sum_{j} w_{jk}o_j$, $o_k=\\sigma (net_k)$  \n",
    "$$\\frac{\\partial E}{\\partial w_{jk}}=\\frac{\\partial E}{\\partial o_k}\\frac{\\partial o_k}{\\partial net_k}\\frac{\\partial net_k}{\\partial w_{jk}}=-(t_k-o_k)o_k(1-o_k)o_j=-\\delta_ko_j$$\n",
    "$$w_{jk}^{t+1} \\leftarrow w_{jk}^t - \\eta \\frac{\\partial E}{\\partial w_{jk}}=w_{jk}^t + \\eta \\delta_ko_j $$\n",
    "$$\\eta : learning rate, \\delta_k=(t_k-o_k)o_k(1-o_k)$$\n",
    "\n",
    "마찬가지의 방법으로 two depth layer에 해당하는 $w_{ij}$을 update할 수 있습니다.\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{ij}}= \\sum_{k} \\frac{\\partial E}{\\partial o_k}\\frac{\\partial o_k}{\\partial net_k}\\frac{\\partial net_k}{\\partial o_j}\\frac{\\partial o_j}{\\partial net_j}\\frac{\\partial net_j}{\\partial w_{ij}}=\\sum_{k} -(t_k-o_k)o_k(1-o_k) \\frac{\\partial net_k}{\\partial o_j}\\frac{\\partial o_j}{\\partial net_j}\\frac{\\partial net_j}{\\partial w_{ij}}=\\sum_{k} \\delta_k\\times w_{jk} \\times o_j(1-o_j)\\times o_i=-o_j(1-o_j)\\sum_{k} \\delta_k w_{jk} \\times o_i= -\\delta_j o_i$$\n",
    "$$w_{ij}^{t+1} \\leftarrow w_{ij}^t - \\eta \\frac{\\partial E}{\\partial w_{ij}}=w_{ij}^t + \\eta \\delta_ko_j $$\n",
    "$$\\delta_j=o_j(1-o_j)\\sum_{k} \\delta_k w_{jk}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Neural Network with MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "@ copyright: AAI lab (http://aailab.kaist.ac.kr/xe2/page_GBex27)\n",
    "@ author: Moon Il-chul: icmoon@kaist.ac.kr\n",
    "@ annotated by Shin Dong-hyeok: tlsehdgur0@kaist.ac.kr\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# tensorflow로부터 mnist data를 불러옴\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100 # n : Hidden Layer에서 node의 갯수\n",
    "\n",
    "# batch와 epoch size 결정\n",
    "batch_size = 100 # batch size : 한 번 iteration을 실행할 때 사용하는 데이터의 갯수 \n",
    "total_batch = int(mnist.train.num_examples / batch_size) # total batch : 전체 batch의 갯수\n",
    "epoch_size = 80 # epoch size : 전체 iteration의 횟수 \n",
    "total_costs = np.zeros(epoch_size) # total_costs : 각 epoch마다 total cost를 저장\n",
    "\n",
    "# logistic function 정의\n",
    "def Logis(x):\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight & Bias term initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization을 이용하여 weight와 biase의 초기값 부여\n",
    "w1 = np.random.uniform(-np.sqrt(6.0/(784+n)),np.sqrt(6.0/(784+n)),(784,n))\n",
    "b1 = np.random.uniform(-np.sqrt(6.0/(784+n)), np.sqrt(6.0/(784+n)),(1,n))\n",
    "\n",
    "w2 = np.random.uniform(-np.sqrt(6.0/(n+10)),np.sqrt(6.0/(n+10)),(n,10))\n",
    "b2 = np.random.uniform(-np.sqrt(6.0/(n+10)),np.sqrt(6.0/(n+10)),(1,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackPropagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0010 cost = 0.21880\n",
      "Epoch :  0020 cost = 0.20090\n",
      "Epoch :  0030 cost = 0.19048\n",
      "Epoch :  0040 cost = 0.18459\n",
      "Epoch :  0050 cost = 0.17957\n",
      "Epoch :  0060 cost = 0.17663\n",
      "Epoch :  0070 cost = 0.17345\n",
      "Epoch :  0080 cost = 0.17168\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNEhlISIiDfr/iViO+3AZ9EMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2839a19d240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization complete\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_size): # epoch_size만큼 반복실행\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size) \n",
    "        X = batch_xs # batch size만큼의 training Input(=image 벡터) \n",
    "        Y = batch_ys # batch size만큼의 training supervision(=각 image의 label)\n",
    "        \n",
    "        '''forward-pass of neural network'''\n",
    "        L1 = np.matmul(X,w1)+b1 # Hidden Layer의 input activation function, L1 = b1 + W1*X\n",
    "        L1 = Logis(L1) # Hidden Layer의 output activation function with logistic function \n",
    "\n",
    "        L2 = np.matmul(L1,w2)+b2 # Output Layer의 input activation function, L2 = b2 + W2*L1\n",
    "        Y_hat = np.exp(L2)/np.exp(L2).sum(axis=1).reshape(-1,1) # Output Layer의 output activation function with softmax function \n",
    "\n",
    "        '''backward-pass of neural network'''\n",
    "        delt_1 = np.dot(np.dot(Y_hat,np.ones((10,batch_size))-Y_hat.T),Y-Y_hat) # delta signal1 = (Y-Y_hat)Y_hat(1-Y_hat)\n",
    "        w2_gradient = (-np.dot(L1.T,delt_1))/batch_size # gradient of w2 = - delt_1*L1\n",
    "        b2_gradient = (-np.average(delt_1, axis=0)) # gradient of b2\n",
    "\n",
    "        delt_2 = np.dot(delt_1,w2.T)*L1*(1-L1) # delta signal2 = L1(1-L1)(delt_1*w2)\n",
    "        # 앞서 Output Layer의 output activation function은 softmax function로 설정했지만,\n",
    "        # binary case에서는 softmax와 logistic function이 동일한 형태를 가지므로 logistic function의 derivative 성질을 사용할 수 있습니다.\n",
    "        w1_gradient = (-np.dot(X.T,delt_2))/batch_size # gradient of w1 = - delt_2*X\n",
    "        b1_gradient = (-np.average(delt_2, axis=0)) # gradient of b1\n",
    "\n",
    "        '''weight update'''\n",
    "        learning_rate = 0.001\n",
    "        w2 -= learning_rate*w2_gradient\n",
    "        b2 -= learning_rate*b2_gradient\n",
    "        w1 -= learning_rate*w1_gradient\n",
    "        b1 -= learning_rate*b1_gradient\n",
    "\n",
    "        total_cost += np.mean(0.5*np.square(Y-Y_hat)) # total cost = 1/2(sum of (Y-Y_hat)^2)\n",
    "        \n",
    "    total_cost = total_cost/batch_size\n",
    "    total_costs[epoch] = total_cost\n",
    "    if epoch % 10 == 9:\n",
    "        print('Epoch : ', '%04d' % (epoch+1), 'cost =', '%.5f' % (total_cost))\n",
    "\n",
    "plt.plot(total_costs)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('cost')\n",
    "plt.show()\n",
    "print('optimization complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과해석부1\n",
    "\n",
    "위의 출력문과 그래프는 epoch 값과 각 epoch에서의 total cost를 나타낸 것입니다.  \n",
    "Training을 진행할수록(Epoch가 증가할수록), total cost가 꾸준히 감소함을 확인할 수 있습니다.  \n",
    "이는 경사하강법을 이용하여 Single Neural Network가 유의미하게 learning 되었음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Test (Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is : 0.84960\n"
     ]
    }
   ],
   "source": [
    "'''classification accuracy test'''\n",
    "X_test = mnist.test.images # Test set의 Input(=image 벡터)\n",
    "Y_test = mnist.test.labels # Test set의 supervision(=각 image의 label)\n",
    "\n",
    "L1_test = np.matmul(X_test,w1)+b1\n",
    "L1_test = Logis(L1_test)\n",
    "L2_test = np.matmul(L1_test,w2)+b2\n",
    "Y_hat_test = np.exp(L2_test)/np.exp(L2_test).sum(axis=1).reshape(-1,1)\n",
    "\n",
    "is_correct = np.equal(np.argmax(Y_hat_test,1),np.argmax(Y_test,1)) # Y_hat과 supervision의 일치하는 횟수를 count\n",
    "accuracy = np.sum(is_correct.astype(int))*0.0001\n",
    "\n",
    "print ('accuracy is :','%.5f' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 해석부2\n",
    "\n",
    "위는 해당 모델의 성능을 측정하기 위해 Test set을 이용하여 정확도를 측정한 결과입니다.  \n",
    "동일 input에 대하여 단일 인공 신경망을 이용한 추정값 $\\hat{y}$과 실제 label y의 일치 횟수를 count하여 정확도를 측정하였습니다.  \n",
    "그 결과, 학습에 사용되었던 Training set뿐 아니라 새로운 데이터인 Test set에 대해서도 Single Neural Network가 잘 실행됨을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
